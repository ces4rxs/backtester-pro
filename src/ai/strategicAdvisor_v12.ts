// src/ai/strategicAdvisor_v12.ts â€” ğŸ§  OMEGA Strategic Decision Engine v12
// - No modifica mÃ³dulos previos (v7.1â€“v11)
// - Fusiona proyecciÃ³n cognitiva (v11) con razonamiento estratÃ©gico y priorizaciÃ³n
// - Uso: /ai/learn/v12/:id

import { generateNeuralAdvisorV11 } from "./neuralAdvisor_v11.js";

type StrategyDecision = {
Â  id: string;
Â  decision: "HOLD" | "ADAPT" | "REINFORCE" | "RETRAIN";
Â  confidence: number;
Â  rationale: string;
Â  expectedReturn: number;
Â  riskScore: number;
Â  recommendedAction: string;
};

function normalize(x: number, min: number, max: number): number {
Â  if (max === min) return 0.5;
Â  return Math.max(0, Math.min(1, (x - min) / (max - min)));
}

export function generateStrategicAdvisorV12(strategyId: string) {
Â  // ğŸ”¹ 1. Reusar el v11 para obtener mÃ©tricas reflexivas
Â  const v11 = generateNeuralAdvisorV11(strategyId);

  // ğŸ”½ğŸ”½ğŸ”½ (LÃNEA 26 CORREGIDA) ğŸ”½ğŸ”½ğŸ”½
const stats = (v11?.stats ?? {}) as any;  // ğŸ”¼ğŸ”¼ğŸ”¼ (LÃNEA 26 CORREGIDA) ğŸ”¼ğŸ”¼ğŸ”¼

Â  const sharpe = Number(stats.projectedSharpe || 0);
Â  const mdd = Number(stats.projectedMDD || -0.02);
Â  const cagr = Number(stats.projectedCAGR || 0.03);
Â  const stability = Number(stats.stabilityIndex || 0.7);
Â  const antiOverfit = Number(stats.antiOverfit || 0.5);
Â  const v11Score = Number(stats.v11Score || 0);

Â  // ğŸ”¹ 2. Calcular "risk-adjusted alpha"
Â  const alpha = sharpe * (1 - Math.abs(mdd)) + cagr * 10 * stability;
Â  const riskScore = Math.max(0, 1 - stability * 0.6 - antiOverfit * 0.3 + Math.abs(mdd) * 1.2);
Â  const confidence = Math.min(0.98, 0.65 + stability * 0.25 + antiOverfit * 0.1);

Â  // ğŸ”¹ 3. ClasificaciÃ³n de acciÃ³n recomendada
Â  let decision: StrategyDecision["decision"] = "HOLD";
Â  let rationale = "Sin cambios significativos.";
Â  let action = "Mantener estructura de estrategia y validar semanalmente.";
Â  if (alpha < 0 || riskScore > 0.7) {
Â  Â  decision = "RETRAIN";
Â  Â  rationale = "La estrategia muestra degradaciÃ³n y alta dispersiÃ³n cognitiva.";
Â  Â  action = "Reentrenar modelo y ejecutar nueva simulaciÃ³n Monte Carlo.";
Â  } else if (alpha > 1.5 && stability > 0.8) {
Â  Â  decision = "REINFORCE";
Â  Â  rationale = "DesempeÃ±o robusto con coherencia reflexiva estable.";
Â  Â  action = "Escalar posiciÃ³n o replicar estrategia en entorno controlado.";
Â  } else if (stability < 0.5) {
Â  Â  decision = "ADAPT";
Â  Â  rationale = "Volatilidad cognitiva detectada â€” se sugiere recalibraciÃ³n leve.";
Â  Â  action = "Ajustar parÃ¡metros de entrada o filtros de riesgo.";
Â  }

Â  // ğŸ”¹ 4. EstimaciÃ³n de retorno esperado (simulada)
Â  const expectedReturn = Number((cagr * (1 - riskScore) * 100).toFixed(2));

Â  // ğŸ”¹ 5. Generar estructura completa
Â  const decisionObj: StrategyDecision = {
Â  Â  id: strategyId,
Â  Â  decision,
Â  Â  confidence: Number(confidence.toFixed(3)),
Â  Â  rationale,
Â  Â  expectedReturn,
Â  Â  riskScore: Number(riskScore.toFixed(3)),
Â  Â  recommendedAction: action,
Â  };

Â  // ğŸ”¹ 6. Reporte estratÃ©gico completo
Â  return {
Â  Â  summary: "OMEGA Strategic Advisor v12 â€” Decision Engine",
Â  Â  mode: "v12",
Â  Â  baseModel: "v11 Reflexive Cognition Core",
Â  Â  strategyId,
Â  Â  decision: decisionObj,
Â  Â  meta: {
Â  Â  Â  version: "v12.0",
Â  Â  Â  alpha,
Â  Â  Â  stability,
Â  Â  Â  antiOverfit,
Â  Â  Â  source: "internal-reflexive-simulation",
Â  Â  },
Â  Â  note: "SimulaciÃ³n educativa. No implica recomendaciÃ³n de inversiÃ³n real.",
Â  };
}